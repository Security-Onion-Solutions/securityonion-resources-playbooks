name: ET HUNTING robots Request (set)
id: 1249656
description: |
  Detects HTTP GET requests for robots.txt files with specific characteristics.
  May indicate automated scanning, crawling activity, or reconnaissance attempts.
type: detection
detection_id: 2044538
detection_category: ''
detection_type: nids
contributors:
  - SecurityOnionSolutions
created: 2024-01-15
questions:
  - question: What was the complete HTTP request for the robots file?
    context: Shows the exact request structure and headers that triggered this detection.
    range: +/-15m
    query: |
      aggregation: false
      logsource:
        category: network
        service: http
      detection:
        selection:
          community_id: '{network.community_id}'
        condition: selection
      fields:
        - http.method
        - http.useragent
        - http.virtual_host
        - http.uri
        - http.status_code
  - question: Does this host normally access robots.txt files on external sites?
    context: Determines if this represents typical web browsing or automated behavior.
    range: -7d
    query: |
      aggregation: true
      logsource:
        category: network
        service: http
      detection:
        selection:
          dst_ip: '{destination.ip}'
        condition: selection
      fields:
        - dst_ip
  - question: What process initiated this robots.txt request?
    context: Identifies the application making the request, distinguishing between browsers and automated tools.
    range: +/-15m
    query: |
      aggregation: false
      logsource:
        category: network
      detection:
        selection:
          community_id: '{network.community_id}'
        filter:
          Image|exists: true
        condition: selection and filter
      fields:
        - hostname
        - User
        - Image
        - CommandLine
        - ProcessGuid
  - question: What other robots.txt requests occurred from this host?
    context: Reveals patterns of scanning or crawling behavior across multiple targets.
    range: +/-6h
    query: "aggregation: false\nlogsource:\n  category: network\n  service: http\ndetection:\n  selection:\n    src_ip: '{source.ip}'\n    http.method: \"GET\"\n    http.uri|contains: \"/robots\"\n  condition: selection\nfields:\n  - dst_ip\n  - http.virtual_host\n  - http.uri\n  - http.user_agent\n  \n"
  - question: What other external connections occurred from this host?
    context: Identifies additional web requests or reconnaissance activity.
    range: +/-10m
    query: |
      aggregation: false
      logsource:
        category: network
        service: connection
      detection:
        selection:
          src_ip: '{source.ip}'
        private:
          dst_ip|cidr:
            - '10.0.0.0/8'
            - '127.0.0.0/8'
            - '172.16.0.0/12'
            - '192.168.0.0/16'
            - '169.254.0.0/16'
        filter:
          dst_ip: '{network.public_ip}'
        condition: selection and not (private or filter)
      fields:
        - dst_ip
        - dst_port
        - network.transport
        - connection.state_description
  - question: Are other hosts making similar robots.txt requests?
    context: Determines if this is part of coordinated scanning activity.
    range: +/-24h
    query: |
      aggregation: true
      logsource:
        category: alert
      detection:
        selection:
          dst_ip: '{network.public_ip}'
        condition: selection
      fields:
        - src_ip
        - rule.name
        - rule.category
  - question: What user-agent patterns were used in these requests?
    context: Helps identify automated tools versus legitimate browsers.
    range: +/-2h
    query: "aggregation: false\nlogsource:\n  category: network\n  service: http\ndetection:\n  selection:\n    src_ip: '{source.ip}'\n    http.uri|contains: \"/robots\"\n  condition: selection\nfields:\n  - http.user_agent\n  - dst_ip\n  - http.virtual_host\n  \n"
  - question: Did any web crawling or scanning tools execute on this host?
    context: Identifies processes associated with automated web reconnaissance.
    range: +/-30m
    query: |
      aggregation: false
      logsource:
        category: process_creation
      detection:
        selection:
          host.ip: '{network.private_ip}'
          Image|contains:
          - curl.exe
          - wget.exe
          - nmap.exe
          - python.exe
          - powershell.exe
        condition: selection
      fields:
        - User
        - Image
        - CommandLine
        - ParentImage
        - ProcessGuid
  - question: What DNS queries preceded these robots.txt requests?
    context: Shows domain resolution patterns that may indicate scanning targets.
    range: -5m
    query: |
      aggregation: false
      logsource:
        category: network
        service: dns
      detection:
        selection:
          src_ip: '{source.ip}'
        condition: selection
      fields:
        - dns.query.name
        - dns.query.type_name
        - dns.resolved_ip
