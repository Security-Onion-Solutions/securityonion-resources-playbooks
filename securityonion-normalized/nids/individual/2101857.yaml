name: GPL WEB_SERVER robot.txt access
id: 1249267
description: |
  Detects HTTP requests for robot.txt files, which are commonly accessed by web crawlers and bots.
  May indicate legitimate search engine indexing, automated tools, or reconnaissance activity.
type: detection
detection_id: 2101857
detection_category: ''
detection_type: nids
contributors:
  - SecurityOnionSolutions
created: 2024-01-15
questions:
  - question: What was the complete HTTP request for the robot.txt file?
    context: Reveals the full request details including user-agent and headers.
    range: +/-15m
    query: |
      aggregation: false
      logsource:
        category: network
        service: http
      detection:
        selection:
          community_id: '{network.community_id}'
        condition: selection
      fields:
        - http.method
        - http.useragent
        - http.virtual_host
        - http.uri
        - http.status_code
  - question: Does this host normally receive requests for robot.txt files?
    context: Determines if robot.txt access is typical for this web server.
    range: -7d
    query: |
      aggregation: true
      logsource:
        category: network
        service: http
      detection:
        selection:
          dst_ip: '{destination.ip}'
        condition: selection
      fields:
        - dst_ip
  - question: What other web server files were requested by this source IP?
    context: Identifies additional web server enumeration or crawling activity.
    range: +/-2h
    query: |
      aggregation: false
      logsource:
        category: network
        service: http
      detection:
        selection:
          src_ip: '{source.ip}'
          dst_ip: '{destination.ip}'
          http.method: GET
        condition: selection
      fields:
        - http.uri
        - http.user_agent
        - http.status_code
  - question: What external connections occurred from this web server after the robot.txt request?
    context: Identifies potential data exfiltration or callback connections.
    range: +/-10m
    query: |
      aggregation: false
      logsource:
        category: network
        service: connection
      detection:
        selection:
          src_ip: '{source.ip}'
        private:
          dst_ip|cidr:
            - '10.0.0.0/8'
            - '127.0.0.0/8'
            - '172.16.0.0/12'
            - '192.168.0.0/16'
            - '169.254.0.0/16'
        filter:
          dst_ip: '{network.public_ip}'
        condition: selection and not (private or filter)
      fields:
        - dst_ip
        - dst_port
        - network.transport
        - connection.state_description
  - question: Are multiple web servers receiving robot.txt requests from the same source?
    context: Determines if this is part of broader reconnaissance activity.
    range: +/-6h
    query: |
      aggregation: false
      logsource:
        category: network
        service: http
      detection:
        selection:
          src_ip: '{source.ip}'
          http.uri|contains: "robot"
        condition: selection
      fields:
        - dst_ip
        - http.virtual_host
        - http.uri
        - http.user_agent
  - question: What is the user-agent pattern of requests accessing robot.txt?
    context: Identifies whether requests come from legitimate crawlers or automated tools.
    range: +/-1h
    query: |
      aggregation: false
      logsource:
        category: network
        service: http
      detection:
        selection:
          src_ip: '{source.ip}'
          http.uri|contains: "robot"
        condition: selection
      fields:
        - http.user_agent
        - http.uri
  - question: Did the same source IP attempt to access common web application directories?
    context: Reveals broader web application enumeration beyond robot.txt access.
    range: +/-2h
    query: |
      aggregation: false
      logsource:
        category: network
        service: http
      detection:
        selection:
          src_ip: '{source.ip}'
          http.uri|contains:
            - "/admin"
            - "/wp-admin"
            - "/phpmyadmin"
            - "/manager"
            - "/cgi-bin"
            - "/backup"
            - "/.git"
            - "/.env"
        condition: selection
      fields:
        - http.uri
        - http.status_code
        - dst_ip
  - question: What web crawling or scanning tools are being used against this server?
    context: Identifies specific tools or bots conducting web reconnaissance.
    range: +/-6h
    query: |
      aggregation: false
      logsource:
        category: network
        service: http
      detection:
        selection:
          dst_ip: '{destination.ip}'
          http.user_agent|contains:
            - "bot"
            - "crawler"
            - "spider"
            - "scan"
            - "nmap"
            - "nikto"
            - "dirb"
            - "gobuster"
        condition: selection
      fields:
        - src_ip
        - http.user_agent
        - http.uri
  - question: Are there related web application alerts from this source IP?
    context: Identifies coordinated web application attack patterns.
    range: +/-24h
    query: |
      aggregation: false
      logsource:
        category: alert
      detection:
        selection:
          related_ip: '{related.ip}'
        filter:
          document_id: '{soc_id}'
        condition: selection and not filter
      fields:
        - rule.name
        - rule.category
        - src_ip
        - dst_ip
